{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe20d28-6a95-4464-81c0-8c4bdceee067",
   "metadata": {},
   "source": [
    "# Using the Deployed agent\n",
    "\n",
    "Now that we've got it deployed and hosted, let's see how we can interface with it through their python SDK\n",
    "\n",
    "There is also, of course, [a more involved API](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html) for production ready environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6d7aee-0be8-48a5-86e5-309232645e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thread_id': 'bec69f2b-e648-4837-9a49-ecb23314afd5', 'created_at': '2024-07-12T20:53:09.838222+00:00', 'updated_at': '2024-07-12T20:53:09.838222+00:00', 'metadata': {}, 'status': 'idle'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client(url=\"https://byo-chatgpt-4489e8808ae65dc39c634b79a9031f9e-ffoprvkqsa-uc.a.run.app\")\n",
    "# create thread\n",
    "thread = await client.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85e3091-d2ae-47d9-86d8-64d48f95896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "{'run_id': '1ef4090c-6b66-68dd-8b79-ebc591de23e2'}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'agent': {'messages': [{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_dN5xxh7zOZ7XRtcxpzzG2jfY', 'function': {'arguments': '{\"prompt\":\"a surreal and artistic representation of the rain\"}', 'name': 'generate_dalle_image'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, 'type': 'ai', 'name': None, 'id': 'run-34a7d1fa-5bae-41a9-93e5-d81b40775bb3', 'example': False, 'tool_calls': [{'name': 'generate_dalle_image', 'args': {'prompt': 'a surreal and artistic representation of the rain'}, 'id': 'call_dN5xxh7zOZ7XRtcxpzzG2jfY'}], 'invalid_tool_calls': [], 'usage_metadata': None}]}}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'tools': {'messages': [{'content': 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-V9dfKsKmgBG4voYBmvfUac3K/user-GXGJJ8NRlcHUZkhkd9I341PB/img-O5hTKLVFEoKbMY742qqpidnC.png?st=2024-07-12T19%3A53%3A35Z&se=2024-07-12T21%3A53%3A35Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-12T20%3A47%3A53Z&ske=2024-07-13T20%3A47%3A53Z&sks=b&skv=2023-11-03&sig=k9PjyN2VPKvcB/arFWd%2BZBMJgAtrb2wUF2JtJ8XYJEE%3D', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'generate_dalle_image', 'id': 'cd974e2c-ba97-4c8a-b5b3-201b1a320b0d', 'tool_call_id': 'call_dN5xxh7zOZ7XRtcxpzzG2jfY', 'raw_output': None}]}}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'agent': {'messages': [{'content': 'Here is the surreal and artistic representation of the rain:\\n\\n![Rain](https://oaidalleapiprodscus.blob.core.windows.net/private/org-V9dfKsKmgBG4voYBmvfUac3K/user-GXGJJ8NRlcHUZkhkd9I341PB/img-O5hTKLVFEoKbMY742qqpidnC.png?st=2024-07-12T19%3A53%3A35Z&se=2024-07-12T21%3A53%3A35Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-12T20%3A47%3A53Z&ske=2024-07-13T20%3A47%3A53Z&sks=b&skv=2023-11-03&sig=k9PjyN2VPKvcB/arFWd%2BZBMJgAtrb2wUF2JtJ8XYJEE%3D)', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, 'type': 'ai', 'name': None, 'id': 'run-2df22dd0-1533-4e61-8e4e-cc6e565149ea', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]}}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: end...\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"human\",\n",
    "            \"content\": \"can you make me a picture of the rain\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "chunks = []\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    chunks.append(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39781c4-7f0e-42a7-a7a1-4574dfb401f1",
   "metadata": {},
   "source": [
    "---\n",
    "# Quick Interface Example\n",
    "\n",
    "Using the python SDK and gradio, making a super simple quick chatbot interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323334c4-207f-44b3-b9b3-dbbeadb7f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "from langgraph_sdk import get_client\n",
    "import os\n",
    "\n",
    "URL = \"https://byo-chatgpt-4489e8808ae65dc39c634b79a9031f9e-ffoprvkqsa-uc.a.run.app\"\n",
    "API_KEY = os.environ[\"LANGSMITH_API_KEY\"]\n",
    "\n",
    "async def setup():\n",
    "    client = get_client(url=URL, api_key=API_KEY)\n",
    "    assistants = await client.assistants.search()\n",
    "    assistant = assistants[0]\n",
    "    thread = await client.threads.create()\n",
    "    return assistant[\"assistant_id\"], thread['thread_id']\n",
    "\n",
    "assistant_id = None\n",
    "thread_id = None\n",
    "\n",
    "async def chat(message):\n",
    "    global assistant_id, thread_id\n",
    "    \n",
    "    if assistant_id is None or thread_id is None:\n",
    "        assistant_id, thread_id = await setup()\n",
    "    \n",
    "    client = get_client(url=URL, api_key=API_KEY)\n",
    "    input_data = {\"messages\": [{\"role\": \"user\", \"content\": message}]}\n",
    "    \n",
    "    full_response = \"\"\n",
    "    tool_calls = []\n",
    "    async for chunk in client.runs.stream(\n",
    "        thread_id,\n",
    "        assistant_id,\n",
    "        input=input_data,\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        if chunk.data and chunk.event != \"metadata\":\n",
    "            if 'messages' in chunk.data.get('agent', {}):\n",
    "                for msg in chunk.data['agent']['messages']:\n",
    "                    if msg.get('type') == 'ai':\n",
    "                        tool_calls.extend(extract_tool_calls(msg))\n",
    "                        full_response += msg.get('content', '')\n",
    "\n",
    "    return tool_calls, full_response if full_response else \"No response generated.\"\n",
    "\n",
    "def extract_tool_calls(message):\n",
    "    calls = []\n",
    "    if 'tool_calls' in message:\n",
    "        for call in message['tool_calls']:\n",
    "            call_description = f\"Tool call: {call['name']} with args: {call['args']}\"\n",
    "            calls.append(call_description)\n",
    "    return calls\n",
    "\n",
    "def user(user_message, history):\n",
    "    return \"\", history + [[user_message, None]]\n",
    "\n",
    "def bot(history):\n",
    "    user_message = history[-1][0]\n",
    "    tool_calls, bot_message = asyncio.run(chat(user_message))\n",
    "    \n",
    "    new_history = list(history)\n",
    "    if tool_calls:\n",
    "        tool_call_text = \"\\n\".join(tool_calls)\n",
    "        new_history.append((None, tool_call_text))\n",
    "    \n",
    "    new_history.append((None, bot_message))\n",
    "    \n",
    "    return new_history\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Base()) as demo:\n",
    "    chatbot = gr.Chatbot(bubble_full_width=False)\n",
    "    msg = gr.Textbox()\n",
    "    submit = gr.Button(\"Submit\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e963ecb-a22c-40ff-9b41-6f1673af73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425aa23c-f771-473d-9af8-6d300a8027af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
